# This script performs the actual learning - it reads in the frames generated by `compoundViewGenerator.py`
# and the related position vectors and attempts to train a neural network to localise position based on the
# view.
# Note that this script can only be run after the image data has been generaated at least for the compound
# eye specified in `dataRootFile` and `dataType`.


import torch
from torch import nn
import torch.nn.functional as F
from torchvision.transforms import Normalize
from torchvision import transforms

from torch.utils.data import Dataset
from torch.utils.data import IterableDataset
#from torchvision import datasets
from torchvision.transforms import ToTensor
import matplotlib.pyplot as plt
from torch.utils.data import DataLoader
import numpy as np
import time
import math
from pathlib import Path
from skimage import io
import sys
import datetime
from compoundRayIterators import UniformCubeIterator

DEBUG_MODE = False              # Whether in debug mode or not
SHOW_GRAPH = True               # Whether to show the learning graph
EXPORT_UNIFORM_CUBE = True      # Whether to save the uniform sample cube after learning
EXPORT_LEARNING_GRAPH = True    # whether to export learning graph data
EXPORT_NETWORK = True           # Whether to save the network after running
PRE_COMPUTED_RESULT_NORMS = {"means": np.zeros(3), "stds": np.ones(3)*14.5} # Set to "None" to force computed result norms

dataRootFile = "data/eye-distance-data/AM_60186" # Specifies which compound eye data we're looking at
dataType = "split" # Specifies which sub-variety of compound eye we're looking at

class CompoundRayFileDataset(Dataset):
  def __init__(self, dataRoot="data/eye-distance-data/AM_60185", dataType="real", debug=False, bottomPct=None, topPct=None, transform=None, normalizeResult=False, fixedResultNormalisationData=None):
    super(CompoundRayFileDataset).__init__()
    self.debug = debug
    self.imageFolder = Path(dataRoot)/dataType
    # Store the distances data in a big numpy array
    with open(Path(dataRoot) / (dataType + "-distances.csv")) as f:
      directionVectors = []
      filenames = []
      for line in f:
        lineData = line.split(",")
        directionVectors.append([float(n) for n in lineData[1:]])
        filenames.append(int(lineData[0]))
      self.directionVectors = np.asarray(directionVectors)
      self.filenames = np.asarray(filenames)

    # Make sure there is at least one point of data to use
    assert len(self) >= 1

    # Clip to either the bottom % or top % if either are specified so that we can have train and test datasets
    if(bottomPct != None):
      split = int(math.floor(len(self)*bottomPct))
      self.directionVectors = self.directionVectors[:split]
      self.filenames = self.filenames[:split]

    if(topPct != None):
      split = int(math.floor(len(self)*topPct))
      self.directionVectors = self.directionVectors[split:]
      self.filenames = self.filenames[split:]

    # Get the image size by opening the first file and reading it's length (only taking the red component [it's black and white)
    self.imageSize = io.imread(self.imageFolder/("{:d}.ppm".format(self.filenames[0])))[:,:,0].size
    
    # If there was a transform, add it
    self.tf = transform

    # Result normalisation
    if fixedResultNormalisationData == None:
      if normalizeResult:
        # Then get the mean across the results
        means = np.mean(self.directionVectors, axis=0)
        stds = np.std(self.directionVectors, axis=0)
        self.resultNormalisationData = {"means": means, "stds": stds}
      else:
        self.resultNormalisationData = None
    else:
      # Option to pass pre-computed normalisation data
      self.resultNormalisationData = fixedResultNormalisationData

    if(self.debug):
      print("New dataset created with", len(self), "objects.")
      print("\tImage length (raw)   :", self.imageSize)
      print("\tImage length (pixels):", int(self.imageSize/3))
      if(self.resultNormalisationData != None):
        print("\tResult Means:", self.resultNormalisationData["means"])
        print("\tResult stds: ", self.resultNormalisationData["stds"])
  
  def __len__(self):
    return self.directionVectors.shape[0]

  def __getitem__(self, idx):
    if torch.is_tensor(idx):
      idx = idx.tolist()

    imgPath = self.imageFolder/("{:d}.ppm".format(self.filenames[idx]))
    image = io.imread(imgPath)[:,:,0].astype(np.float32)
    vector = self.directionVectors[idx]

    if(self.debug):
      print("Loaded image info:")
      print("\tPath:", imgPath)
      print("\tDirection:", vector)

    #return ({"image": torch.from_numpy(image), "direction": torch.from_numpy(vector)})
    imageOut = image
    vectorOut = vector
    #imageOut = torch.from_numpy(image).float()
    #vectorOut = torch.from_numpy(vector).float()

    if (self.tf != None):
      imageOut = self.tf(imageOut)
    if (self.resultNormalisationData != None):
      vectorOut = (vectorOut - self.resultNormalisationData["means"])/self.resultNormalisationData["stds"]

    vectorOut = vectorOut.astype(np.float32) # Explicitly cast to float (32bit) rather than double (64bit)

    return (imageOut, vectorOut)


arglen = len(sys.argv)
if arglen >= 2:
  dataType = sys.argv[1]
if arglen >= 3:
  dataRootFile = "data/eye-distance-data/" + sys.argv[2]

print(f"[Program arguments: {arglen}] Running with datatype \"{dataType}\" on dataset \"{dataRootFile}\"")

t = 0
maxEpochs = 100
testSamplingSize = 100 # 100*100*100 sample cube

if not DEBUG_MODE:
  splitPct = 0.8 # Train on 80% of the data, test on the remaining 20%
else:
  splitPct = 0.1 # Sample quick run
  maxEpochs = 5
  testSamplingSize = 10
trainingDataset = CompoundRayFileDataset(debug=DEBUG_MODE, bottomPct=splitPct, dataRoot=dataRootFile, dataType=dataType)
featureSize = trainingDataset.imageSize

# Get mean and standard deviation
print("Calculating mean and standard deviation for training normalization...")
meanLoader = DataLoader(trainingDataset, batch_size=len(trainingDataset), num_workers=1)
allData = next(iter(meanLoader))
print("Mean and std:")
mean = allData[0].mean()
std = allData[0].std()
print(mean, std)
print("=============")
inputTf = transforms.Compose([ToTensor(), Normalize(mean, std)])


# Create the normalised traning set
normalisedTrainingDataset = CompoundRayFileDataset(debug=DEBUG_MODE, bottomPct=splitPct, transform=inputTf, fixedResultNormalisationData = PRE_COMPUTED_RESULT_NORMS, normalizeResult = True, dataRoot=dataRootFile, dataType=dataType)
normalisedTestingDataset = CompoundRayFileDataset(debug=DEBUG_MODE, topPct=splitPct, transform = inputTf, fixedResultNormalisationData = PRE_COMPUTED_RESULT_NORMS, normalizeResult = True, dataRoot=dataRootFile, dataType=dataType)

# Uncomment for short tests
if DEBUG_MODE:
  normalisedTestingDataset = CompoundRayFileDataset(debug=DEBUG_MODE, topPct=0.95, transform = inputTf, fixedResultNormalisationData = PRE_COMPUTED_RESULT_NORMS, normalizeResult = True, dataRoot=dataRootFile, dataType=dataType)

# Create data loaders from the normalised datasets
trainingDataLoader = DataLoader(normalisedTrainingDataset, batch_size=64, shuffle=True, num_workers=16)
testingDataLoader = DataLoader(normalisedTestingDataset, batch_size=64, shuffle=True, num_workers=16)

# Make the neural network
device = "cuda" if torch.cuda.is_available() else "cpu"
#device = "cpu"
print(f"Using {device} device.")

class NeuralNetwork(nn.Module):
  def __init__(self):
    super(NeuralNetwork, self).__init__()
    self.flatten = nn.Flatten().to(device)
    self.fc1 = nn.Linear(featureSize, 1000).to(device)
    self.fc2 = nn.Linear(1000, 256).to(device)
    self.fc3 = nn.Linear(256, 3).to(device) # Output layer, resolves to 3D position

  def forward(self, x):
    x = torch.flatten(x, 1) # Flatten all dimensions
    # Non-linearities
    x = F.relu(self.fc1(x))
    x = F.relu(self.fc2(x))
    # Output layer
    x = self.fc3(x)
    return x

network = NeuralNetwork()
print(network)
params = list(network.parameters())
print(f"Parameter count: {len(params)}")

# Configure loss function and optimiser
#lossFn = nn.MSELoss(reduction="sum")
lossFn = nn.L1Loss()
optimizer = torch.optim.SGD(network.parameters(), lr=1e-3)

# Quickly print out the first three data points to check they're right:
i = 0
for batch, (X, y) in enumerate(trainingDataLoader):
  i = i+1
  print("batch:", batch)
  print("X:", X)
  print("y:", y)
  if(i >= 3):
    break

# Define training function
def train(dataLoader, model, lossFn, optimizer):
  size = len(dataLoader.dataset)
  model.train()
  for batch, (X, y) in enumerate(dataLoader):
  #for batch, data in enumerate(dataLoader):
      #print("image:", data["image"])
      #print("direction:", data["direction"])
      X, y = X.to(device), y.to(device)

      # Compute prediction error
      pred = model(X)
      loss = lossFn(pred, y)

      ## Backpropagation
      optimizer.zero_grad()
      loss.backward()
      optimizer.step()

      # Debug printing
      if batch % 100 == 0:
          loss, current = loss.item(), batch * len(X)
          print(f"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]")

# Just uses the test loader
def test(dataloader, model, loss_fn):
    size = len(dataloader.dataset)
    num_batches = len(dataloader)
    model.eval()
    test_loss, correct = 0, 0
    with torch.no_grad():
        for X, y in dataloader:
            X, y = X.to(device), y.to(device)
            pred = model(X)
            test_loss += loss_fn(pred, y).item()
    test_loss /= num_batches
    print(f"Test Error: \n Avg loss: {test_loss:>8f} \n")
    return(test_loss)

def testUniformCube(dataIterator, model, lossFn):
  iterator = iter(dataIterator)
  model.eval()
  testLoss = 0
  sampleSize = dataIterator.getSamplingSize()
  lossVol = np.zeros((sampleSize, sampleSize, sampleSize))
  print()
  with torch.no_grad():
    for i in range(dataIterator.getTotalSamplePoints()):
      print("\rSampling cube: {:.2f}%...".format(i/dataIterator.getTotalSamplePoints()*100), end="")

      # Get the loss for this position
      X, y, coord= next(iterator)
      X, y = X.to(device), y.to(device)
      pred = model(X)
      loss = lossFn(pred, y).item()

      # G
      testLoss += loss

      # store loss in loss volume image coordinates
      lossVol[coord[0], coord[1], coord[2]] = loss
  print()

  testLoss /= dataIterator.getTotalSamplePoints();
  print(f"Test Error: \n Avg loss: {testLoss:>8f} \n")
  return(testLoss, lossVol)
    
# Actually train the data
eyeName = Path(dataRootFile).parts[-1]
eyeFilepath = "sim-environment/eyes/" + eyeName + "-" + dataType + ".eye"
uniformIter = UniformCubeIterator(eyeFilepath, debug=False, samplingSize=testSamplingSize, transform=inputTf, resultNormalisationData = PRE_COMPUTED_RESULT_NORMS)
testLosses = []
#while datetime.datetime.now().hour < 10:
while t < maxEpochs:
  t = t + 1
  print(f"Epoch {t}\n-------------------------------")
  train(trainingDataLoader, network, lossFn, optimizer)
  avgLoss = test(testingDataLoader, network, lossFn) # Just use the test data
  #avgLoss, lossVolume  = testUniformCube(uniformIter, network, lossFn) # Use the uniform sampling cube
  testLosses.append(avgLoss);

if EXPORT_LEARNING_GRAPH:
  graphPath = f"data-out/LossGraph-{eyeName}-{dataType}-{testSamplingSize}grid-{maxEpochs}epochs-{splitPct}splitPct"
  np.save(graphPath, np.asarray(testLosses))

if EXPORT_UNIFORM_CUBE:
  avgLoss, lossVolume = testUniformCube(uniformIter, network, lossFn) # Get the final loss volume
  np.save(f"data-out/LossVolume-{eyeName}-{dataType}-{testSamplingSize}grid-{maxEpochs}epochs-{splitPct}splitPct", lossVolume)

if EXPORT_NETWORK:
  print("Saving network.")
  torch.save(network, f"data-out/networks/{eyeName}-{dataType}-{testSamplingSize}grid-{maxEpochs}epochs-{splitPct}splitPct")

if SHOW_GRAPH:
  xs = np.arange(len(testLosses))
  ys = np.asarray(testLosses)
  plt.plot(xs,ys)
  plt.show()
